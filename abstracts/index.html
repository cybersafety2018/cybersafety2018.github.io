<!DOCTYPE html>
<html>
	<head>
		<title>CyberSafety 2016</title>
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<link rel="stylesheet" href="../../css/main.css">
		<script type="text/javascript" src="../../js/jquery-1.12.4.min.js"></script>
		<script type="text/javascript">
			$(document).ready(function(e){
				$('.has-sub').click(function(){
					$(this).toggleClass('tap');
					setTimeout(function(){$(this).focus();},10);
					
				});
				
			});
			
		</script>
	</head>
	<body>
		
		
		<div id="wrapper">
			
		<script type="text/javascript" src="../../includes/title2.js"> </script>
		<script type="text/javascript" src="../../includes/menu2.js"> </script>
			
			<table class="text">
				<tr>
					<td>
						<div>
						<h3>Session 1</h3>
						<table width="600px">
							<tr>
								<td>
								<h4>Bad Actors in Social Media by Francesca Spezzano</h4>
								</td>
							</tr>
							
							<tr>
								<td>
								Abstract:Bad actors seriously compromise social media every day by threatening the safety of the users and the integrity of the content. This keynote speech will give an overview of the state of the art social network analysis, data mining, and machine learning techniques to detect bad actors in social media. More specifically, we will describe both general methods that are platform independent or valid for any malicious user, and methods specific to a particular social media (Twitter, Facebook, Slashdot, Wikipedia, Instagram) and/or a given type of bad actor (bots, spammers, trolls, vandals, cyberbullies). We will group these methods into four broad categories, namely (i) active methods, (ii) content-based, (iii) social network-based, and (iv) behaviorbased, and show their effectiveness in enforcing cybersafety.
								</td>
							</tr>
							
						</table>
						</div>
						
						
					</td>
					
				</tr>
				
				
				<tr>
					<td>
						<div>
						<h3>Session 2</h3>
						<table width="600px">
							<tr>
								<td>
								<h4>Vandals and Hoaxes on the Web by Srijan Kumar</h4>
								</td>
							</tr>
							
							<tr>
								<td>
								Abstract:Web is a space for all, where everybody can read, publish and share information. This has had tremendous positive impact on the lives of billions of people. Wikipedia, being the largest encyclopedia and free, is a major source of information for many. However, since anyone can edit its articles, it is easy to add undesirable content and misinformation. These raise concerns about its credibility and safety, and that of the Web in general. In this talk, I will describe algorithms to identify two different aspects of undesirable actors and acts on Wikipedia: vandals and hoaxes. 
								
First, I will present the state-of-the-art system to detect vandals on Wikipedia called VEWS, which stands for Vandal Early Warning System. Vandals are editors who make unconstructive edits on Wikipedia. VEWS models the editing behavior of all editors on Wikipedia, both benign and vandals, and then builds upon the differences in their behavior to identify the vandals. VEWS achieves an accuracy of over 85% and outperforms ClueBot NG and STiki, the best known algorithms that fight vandalism. Moreover, on average, VEWS detects vandals 2.39 edits before ClueBot NG. Furthermore, the combination of the two gives a fully automatic vandal early warning system with even higher accuracy.
								
Second, I will present an in-depth study of hoaxes on Wikipedia. Hoaxes are fake articles on Wikipedia that are deliberately created to mislead others. By studying over 22,000 hoaxes that have been created on Wikipedia, I will discuss their real-world impact, characteristics and finally, their detection. In terms of impact, while most hoaxes are detected quickly, a small number of hoaxes survive for a long time and are well cited across the Web. The characteristics of hoaxes are defined in terms of article structure and content, embeddedness in the rest of Wikipedia and the creator of the article. Finally, I will discuss an algorithm that uses these findings to determine whether an article is a hoax.
								</td>
							</tr>
							
							
							
							<tr>
								<td>
								<h4>Informing Cyberbullying Research with Social/Psychological Insights by Jeremy Blackburn</h4>
								</td>
							</tr>
							
							<tr>
								<td>
								Abstract:With an unending flow of stories of cyberbullying in online social media, there have been increasing research efforts from the academic community. Unfortunately, this research has been scattered over numerous different topics and disciplines ranging from social and psychological sciences to computer science. In an effort to unify future work, we reviewed the literature across a wide variety of disciplines. Our goal was to determine the level of maturity of the overall community
and identify knowledge gaps that future work should aim to close. In this talk I will present our findings which we believe can be used to inform future work on cyberbullying. In particular, I will discuss the major areas of work that have been covered, and the areas we found to be lacking. Overall, we believe that a multidisciplinary approach which uses qualitative findings to inform quantitative research is needed to address and make progress in combating this social menace.
								</td>
							</tr>
							
							
							
							
						</table>
						</div>
						
						
					</td>
					
				</tr>
				
				
				
				
				
				<tr>
					<td>
						<div>
						<h3>Session 3</h3>
						<table width="600px">
							<tr>
								<td>
								<h4>A Survey of Computational Methods in Cyberbullying Research by Homa Hosseinmardi</h4>
								</td>
							</tr>
							
							<tr>
								<td>
								Abstract:One of the most pressing problems in high schools is bullying. However, with today's online and mobile technologies, bullying is moving beyond the schoolyards via cell phones, social networks, online text, video and images, etc. As bad as fighting and bullying were before the advent of the mobile Internet, the recording and posting of hurtful content online has magnified the harmful reach of bullying, enabling 24/7 bullying. Although cyberbullying may not cause any physical damage initially, it has potentially devastating psychological effects like depression, low self-esteem, suicide ideation, and even suicide. Given the gravity of the consequences cyberbullying has on its victims and its rapid spread among middle and high school students, there is an immediate and pressing need for research to understand how cyber- bullying occurs in OSNs today, so that effective techniques can be developed to accurately detect cyberbullying. Most of the previous research on cyberbullying focused on the psychological component of cyberbullying. Only recently have researchers begun to explore computational methods for detecting cyberbullying. This survey provides insight into the problem of cyberbullying in social networks by investigating existing methods in the research literature. We will first review various computational approaches in analysis, detection and prediction of cyberbullying, harassment and aggressive behavior. Then we discuss the key technical limitations and challenges researchers are facing in this field.
								</td>
							</tr>
							
							
							
							<tr>
								<td>
								<h4>Catching Social Media Advertisers with Strategy Analysis by Meng Jiang</h4>
								</td>
							</tr>
							
							<tr>
								<td>
								Abstract:Advertisers worldwide spent $24 billion to reach consumers on social media in 2015. While such a new way of advertising has successfully
turn the social media into generous profits, the strategies behind it is still mystery to users, advertisers and many businesses. In this paper, we uncover the underlying mechanisms of the social media advertising. Specifically, we compare them with the oldschool advertising strategies that have been widely used since the early 1900s. The advertising on the high tech does not achieve beyond the wisdom of the elders but run faster at a unprecedented scale. We define a series of novel features from the strategies we
discover. We further propose a classification method called SocAdDet based on the SVMs. Experiments on a real social dataset show that SocAdDet can accurately identify different advertising strategies and detect the social promoters. The high accuracy demonstrates that the social media advertising is stronger but not smarter.
								</td>
							</tr>
							
							
							<tr>
								<td>
								<h4>Detecting Cyberbullying using Latent Semantic Indexing by Jacob L. Bigelow, April Edwards Kontostathis, Lynne Edwards</h4>
								</td>
							</tr>
							
							<tr>
								<td>
								Abstract:Cyberbullying has proven consequential to youth Internet users and previous methods relied heavily on the use of manually developed dictionaries. This project describes preliminary results for a system that uses Latent Semantic Indexing (LSI) for the detection of cyberbullying in a labeled collection of posts from Formspring.me. After preprocessing to account for variations in spelling and use of emoticons, a search system was developed. Our system significantly outperforms the baseline with a very simple query and is not dependent on a dictionary of bullying terms.
								</td>
							</tr>
							
							
							
							
						</table>
						</div>
						
						
					</td>
					
				</tr>
				
				
				<tr>
					<td>
						<div>
						<h3>Session 4</h3>
						<table width="600px">
							<tr>
								<td>
								<h4>A Weakly Supervised Approach for Adaptive Detection of Cyberbullying Roles by Bert Huang</h4>
								</td>
							</tr>
							
							<tr>
								<td>
								Abstract:As human communication increasingly occurs through online social networks, online harassment and cyberbullying are becoming a serious social health threat. In this talk, I will introduce an automated, data-driven method for adaptive detection of bullying roles. The model represents whether social media users are instigating bullying, whether they are victimized by bullying, and how indicative certain key phrases are of bullying behavior. The algorithm simultaneously estimates these variables by extrapolating from social media graph data and an expert-provided set of highly indicative bullying phrases. This weak supervision provides training input without requiring excessive effort from human annotators. I will describe quantitative and qualitative experiments on three social media datasets from networks with frequent incidences of cyberbullying: Twitter, Ask.fm, and Instagram. I will conclude by describing a vision of a future where technology helps prevent and mitigate the harm of cyberviolence, placing detection algorithms like the main topic of this talk in context.
								</td>
							</tr>
							
							<tr>
								<td>
								<h4>CyberSafety 2016 Panel Discussion moderated by Jeremy Blackburn</h4>
								</td>
							</tr>
							
							<tr>
								<td>
								Abstract:This panel discussion will revolve around three primary issues: (1) ethics considerations for cybersafety work, (2) bridging the gap between academia and industry, and (3) future growth and concerns for work in this field.
								</td>
							</tr>
							
						</table>
						</div>
						
						
					</td>
					
				</tr>
			</table>
		
		</div>
		
	
	</body>
	
</html> 
